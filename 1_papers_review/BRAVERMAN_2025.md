# Towards a Probabilistic Framework for Analyzing and Improving LLM-Enabled Software

## Abstract

- Los sistemas basados en LLMs son potentes pero **no deterministas.** Es dif√≠cil confiar plenamente en lo que generan o verificar formalmente su comportamiento.
- La **idea central** del paper es: no mirar los *outputs* del LLM como cadenas de texto, sino como ***clusters of semantically equivalent outputs***. 
	- Por ejemplo: todas las respuestas que formalizan una misma propiedad en un c√≥digo.
- ***"Transference Models (TMs):*** concepto definido por los autores, son **LLM center modules** que reciben una entrada (ej. una descripci√≥n) y generan una salida (ej. especificaci√≥n formal). Analizar como se comportan los TMs bajo el LLM es la base del trabajo.
- La **aplicaci√≥n concreta** elegida en el paper es, dado un *docstring*, el modelo debe generar **precondiciones** y **postcondiciones** formales en Dafny.
- Al mirar no solo qu√© responde el modelo, sino c√≥mo reparte la probabilidad entre distintas interpretaciones, se pueden **identificar patrones de error sistem√°ticos**, por ejemplo, cuando el modelo siempre genera una postcondici√≥n d√©bil. 

> Los sistemas que usan LLMs son d√≠ficiles de verificar y depurar. Proponen un enfoque no analiza solo las respuesta, sino la distribuci√≥n de probabilidad **sobre clases sem√°nticas**. Esto los ayuda a identificar errores sistem√°ticos, como respuestas incorrectas con alta confianza. Lo ilustran con el problema de transformar lenguaje natural en especificaciones formales (*autoformalizaci√≥n*). 


## Introducci√≥n

Los LLMs (como GPT-4 y Gemini) funcionan muy bien en muchas tareas gracias a que pueden seguir instrucciones (*"instruction following"*) y aprender del contexto. Esto incluye estrategias como:
- **Zero-shot:** Darle una instrucci√≥n y esperar que entiende qu√© hacer sin ejemplos.
- **Few-shot:** Darle algunos ejemplos en el prompt.

Esta flexibilidad hace que los LLMs se usen cada vez m√°s en aplicaciones reales (*downstream tasks* = tareas derivadas), simplemente d√°ndoles prompts. La **alucinaci√≥n**, es uno de los principales problemas que esto trae. Esto es, el modelo genera cosas que suenan bien, pero son falsas o inv√°lidas. 

Se necesita **entender el comportamiento del sistema.** En el √°mbito de ingenier√≠a de software (de estas cosas), el comportamiento estoc√°stico del modelo es visto m√°s como un problema (por ejemplo, tests que fallan a veces y otras no: *flaky tests*), y no como algo que se pueda analizar o aprovechar

---
‚ö†Ô∏è Se est√° ignorando que el LLM no da una sola respuesta, sino una **distribuci√≥n sobre muchas posibles**??

--- 

La propuesta central es:
1. Identificar qu√© partes del sistema est√°n usando LLMs para transformar informaci√≥n (los **Transference Models**, TMs).
2. Luego, hay que modelar no las salidas en s√≠, sino la **distribuci√≥n de probabilidad sobre clases de significados equivalentes** (lo que llaman *meaning classes*).


**TESIS:** Si entend√©s c√≥mo el LLM reparte probabilidad entre interpretaciones posibles, podemos analizar y mejorar el sistema.


---

**HIP√ìTESIS:**
Si el modelo da una respuesta equivocada **con alta confianza** (concentraci√≥n en una clase err√≥nea), probablemente esa clase de error **tiene una explicaci√≥n sem√°ntica clara**, y por lo tanto se puede **diagnosticar y corregir** el TM.

> Cuando el modelo se equivoca con confianza, dice mucho sobre sus puntos d√©biles y se puede usar eso para mejorar(lo).


### Mis preguntitas:

- El agrupamiento de clases, no depende much√≠simo de la tarea??
- Si una tarea no tiene una √∫nica "clase correcta", c√≥mo se define la alineaci√≥n??
- Es viable para tareas con millones de posibles salidas?

## Preliminares

### A. Large Language Models

**¬øQu√© es un LLM desde el punto de vista t√©cnico?**

Desde el punto de vista t√©cnico, un LLM, b√°sicamente es una **funci√≥n probabil√≠stica param√©trica**. Es decir:
- Toma un input $x$ (un texto anterior, tambi√©n llamado "contexto").
- Y devuelve una distribuci√≥n de probabilidad sobre posibles pr√≥ximos tokens $t_k$:
$$ P(t_k | x)$$ Esto significa que el modelo no genera "una respuesta", sino una **distribuci√≥n sobre todas las respuestas posibles,** token por token.

---

 **¬øC√≥mo se entrena un LLM?**

A trav√©s de _next-token prediction_ (predicci√≥n del pr√≥ximo token). Se entrena con **corpus masivos** de texto, ajustando sus par√°metros para minimizar un error (usualmente entrop√≠a cruzada) entre:

- lo que el modelo predice como pr√≥ximo token, y
- lo que realmente sigue en el texto de entrenamiento.

‚ö†Ô∏è Esto refuerza la idea de que el modelo aprende **probabilidades de continuaci√≥n**, no reglas expl√≠citas o verdades l√≥gicas.

---
**¬øC√≥mo se usa un LLM en la pr√°ctica?**

Una vez entrenado, el modelo puede usarse para generar texto. Para hacerlo, necesita un **decoding strategy**, como:

- _Greedy_: elige siempre el token m√°s probable.
- _Sampling_: elige aleatoriamente seg√∫n la distribuci√≥n.
- _Top-k_ / _Top-p_: limita la elecci√≥n a los tokens m√°s probables.
- _Temperature_: controla cu√°n "creativo" es el modelo (m√°s temperatura = m√°s aleatoriedad).

Esto es crucial porque **el mismo input puede generar diferentes salidas** si el decoding es estoc√°stico.

---
**Conexi√≥n con el paper**

Los autores enfatizan que si bien muchas aplicaciones usan el LLM como una caja negra, ellos quieren **modelar esta distribuci√≥n** para entender el comportamiento del sistema. No les interesa solo ‚Äúqu√© salida dio‚Äù, sino:

> **¬øCon qu√© probabilidad eligi√≥ esa salida sobre otras posibles equivalentes?**

Esto los lleva a analizar _distribuciones sobre clases sem√°nticas_, no solo sobre tokens.


### B .Autoformalization

**¬øQu√© es la autoformalizaci√≥n?**

Autoformalizaci√≥n es el proceso de **convertir texto natural en especificaciones formales.** Es decir, traducir algo como:

> `"""Devuelve el √≠ndice del primer elemento igual a x en el array."""`

en algo como (en lenguaje formal como **Dafny**)

``` dafny
requires a != null
ensures forall i :: 0 <= i < result ==> a[i] != x
ensures a[result] == x
```

Esta tarea requiere **comprensi√≥n sem√°ntica**, **capacidad de inferencia l√≥gica** y conocimiento del dominio del c√≥digo. No es simplemente traducir palabra por palabra.


---
**¬øPor qu√© es importante?**

Porque automatizar esta transformaci√≥n ayuda a tareas cr√≠ticas como:

- **Verificaci√≥n autom√°tica de programas** (probar que el c√≥digo cumple con lo especificado).
- **Pruebas formales** (testings guiados por propiedades).
- **Documentaci√≥n ejecutable** (donde los comentarios se vuelven parte verificable del programa).

Esta es una **tarea dura**, tradicionalmente realizada por expertos. Usar LLMs para esto es ambicioso, pero tambi√©n muy prometedor.

---

**¬øPor qu√© eligieron Dafny?**

- Dafny es un lenguaje dise√±ado para **verificaci√≥n autom√°tica** de programas, con soporte para precondiciones, postcondiciones, invariantes, etc.
- Tiene un **verificador SMT incorporado**, que permite comprobar si las condiciones formales son l√≥gicamente correctas.
- Es usado frecuentemente en papers acad√©micos para tareas de autoformalizaci√≥n y synthesis.

Adem√°s, como el objetivo del paper es evaluar distribuciones sobre significados formales, usar Dafny permite chequear autom√°ticamente **equivalencia sem√°ntica** entre dos especificaciones (v√≠a SMT).

---
**¬øQu√© rol juega esta tarea en el paper?**

Es el **caso de estudio** principal que se usa para aplicar el marco probabil√≠stico. Todo el an√°lisis (alineaci√≥n, concentraci√≥n, mejoras al TM) se ilustra a partir de esta tarea. Lo interesante es que:

- La tarea tiene un **ground truth claro** (las especificaciones correctas est√°n dadas).
- Se puede generar muchas salidas (por el LLM) y verificar si son **equivalentes** entre s√≠.
- Es posible categorizar errores comunes (por ejemplo, _postcondici√≥n d√©bil_, _omisi√≥n de propiedad clave_, _error de sintaxis_).

![[Pasted image 20250613102054.png]]

### C. Transference Models (TMs)

**¬øQu√© es un Transference Model?**

Es una **abstracci√≥n de ingenier√≠a de software** que encapsula c√≥mo un sistema basado en LLM **transforma inputs en outputs** para una tarea particular.

- Es una **unidad funcional** dentro de un sistema m√°s grande.
- Se apoya en un LLM para llevar a cabo una transformaci√≥n (por ejemplo: docstring -> especificaci√≥n Dafny).
- Puede ser tan simple como un prompt, o m√°s complejo (con herramientas externas, reintentos, subm√≥dulos, etc)

``` python 
def doc2spec(docstring):
    prompt = "Given this docstring, write the pre/post conditions: " + docstring
    return LLM(prompt)
```

Este `doc2spec` ser√≠a un **TM**.

---
**¬øPor qu√© los TMs son estoc√°sticos?**

Porque dependen de un LLM, y los LLMs son modelos **probabilisticos:** Dada una entrada $i$, el LLM puede producir distintas salidos $o$, cada una con una probabilidad. Formalmente:
$$T: \mathcal{I} \times \mathcal{O} \rightarrow \mathbb{R} \quad\text{donde}\quad T(i,o) = P(o|i)$$

O sea, el TM **define una distribuci√≥n** sobre salidas posibles para cada entrada. Esto depende fuertemente de:
- El LMM usado.
- El prompt.
- La **estrategia de decodificaci√≥n** (ej. sampling con temperatura, top-k, etc).

---

**¬øQu√© incluye un TM?**

Un TM puede incluir no solo el llamado al LLM, sino tambi√©n:

- **Preprocesamiento** de la entrada (por ejemplo, limpiar el docstring).
- **Razonamiento externo** (RAG, vectores, heur√≠sticas).
- **Postprocesamiento** (validar la salida con el compilador).
- **Loops correctivos**, donde se itera sobre la salida si hubo errores.
- **Cadena de TMs** (uno genera una subparte, otro compone, etc.).

En el paper, muestran un **TM con m√∫ltiples etapas**:

1. Prompt inicial para generar la especificaci√≥n.
2. Si Dafny da error, se corrige usando el mensaje del compilador.
3. Adem√°s, usan un paso estilo RAG para buscar ejemplos similares (doc2vec + retrieval).

---

**¬øPor qu√© es tan importante este concepto?**

Porque los autores **NO** est√°n interesados en estudiar al LLM directamente, sino en estudiar **los sistemas construidos con LLMs**. Es decir:

> "El LLM no es el sistema, sino una parte de un m√≥dulo m√°s grande que transforma datos para una tarea."

Entonces el **objeto de an√°lisis** del paper no es el modelo GPT o Gemini, sino el **TM** como componente de software. El marco propuesto eval√∫a c√≥mo el TM se comporta probabil√≠sticamente:
- Genera siempre la salida correcta?
- Qu√© tanta certeza tiene?
- Hay errores frecuentes con alta probabilidad?

---
**Modelo funcional formal**

Para reforzar: el TM se modela como una funci√≥n probabil√≠stica:

$$T(i, \cdot) = \text{una distribuci√≥n de probabilidad sobre salidas }o \text{ dado un input } i  $$
En otras palabras: **el TM act√∫a como una caja negra estoc√°stica** que recibe una entrada y escupe una distribuci√≥n sobre posibles resultados.

Lo que ellos proponen es: **muestrear esta caja negra** muchas veces con el mismo input, agrupar las salidas en clases de significado equivalentes y analizar esa distribuci√≥n.

### D. Distribution over Semantic Domains

Dado que los LLMs son funciones de estimaci√≥n de densidad sobre secuencias de tokens, los autores coinciden con otros trabajos que la probabilidad deber√≠a considerarse asignada a conceptos, no a cadenas de texto. Muchas veces hay m√∫ltiples (incluso infinitas) cadenas que representan una misma idea (por ejemplo, especificaciones l√≥gicamente equivalentes). En teor√≠a, esos corresponde a sumar las probabilidades asignadas a todas las cadenas dentro de cada clase de equivalencia. 

**¬øCu√°l es el problema de trabajar con cadenas de texto?**

Los LLMs predicen secuencias de tokens (palabras o s√≠mbolos). Eso genera una **distribuci√≥n sobre strings como:**

```
"Returns the index of x" ‚Üí 20%  
"Find the position of x" ‚Üí 18%  
"Locate x in the array" ‚Üí 12%  
```

**Pero** estas cadenas pueden tener el **mismo significado**, aunque est√©n escritas distinto, entonces:

> Analizar solo la cadena m√°s frecuente o el token m√°s probable es **insuficiente** para entender qu√© est√° "pensando" el modelo.

---

**¬øQu√© proponen entonces?**

Agrupar las salidas en **clases sem√°nticas equivalentes** (lo que llaman *meaning classes*). Cada clase agrupa todas las salidas que, aunque tengan forma distinta, expresan la **misma idea.** Por ejemplo si dos f√≥rmulas Dafny dicen: 

``` dafny
ensures exists i :: a[i] == x && forall j < i :: a[j] != x
```

``` dafny
ensures the returned index is the first occurrence of x
```

Estas pueden considerarse **sem√°nticamente equivalentes** (si ambas implican lo mismo). Por tanto, deber√≠an pertenecer a la misma clase. Entonces la **probabilidad total del "concepto"** deber√≠a ser:

$$P(\text{clase}) = \sum_{\text{strings en la clase}} P(\text{string})$$
---
**¬øPor qu√© este punto es crucial?**

Porque al trabajar con LLMs:
- El modelo puede generar miles de variantes textuales **de una misma respuesta sem√°ntica**
- Si evalu√°s solo por exact matching o string similarityu, **subestim√°s la probabilidad del concepto correcto.**

üëâ Entonces, los autores abogan por construir distribuciones **no sobre cadenas**, sino sobre **dominios sem√°nticos abstractos**.

Este cambio de perspectiva es **clave** para su marco probabil√≠stico. Les permite:

- Medir correctamente alineaci√≥n con la verdad.
    
- Detectar errores sem√°nticos aunque el texto ‚Äúsuene bien‚Äù.
    
- Evaluar si el modelo es ‚Äúconfuso‚Äù o ‚Äúseguro‚Äù sem√°nticamente, no solo superficialmente.


### E. Computing Empirical Distributions of TMs

Dado que los TMs se comportan como procesos estoc√°sticos y no siempre se tiene acceso directo a las probabildiades 
